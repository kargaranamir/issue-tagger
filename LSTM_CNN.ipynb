{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kargaranamir/issue-tagger/blob/main/LSTM_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Data Download\n",
        "\n",
        "! wget https://machinehack-be.s3.amazonaws.com/predict_github_issues_embold_sponsored_hackathon/Embold_Participant%27s_Dataset.zip -O data.zip\n",
        "! unzip ./data.zip \n",
        "! mv ./Embold_Participant\\'s_Dataset ./data\n",
        "! rm -rf ./data/sample\\ submission.csv\n",
        "! rm -rf ./data/embold_test.json"
      ],
      "metadata": {
        "id": "Bk6OiGPFudyh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f18895ed-327e-4da6-c004-668cdea5c1a0"
      },
      "id": "Bk6OiGPFudyh",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-06 21:44:12--  https://machinehack-be.s3.amazonaws.com/predict_github_issues_embold_sponsored_hackathon/Embold_Participant%27s_Dataset.zip\n",
            "Resolving machinehack-be.s3.amazonaws.com (machinehack-be.s3.amazonaws.com)... 52.219.66.56\n",
            "Connecting to machinehack-be.s3.amazonaws.com (machinehack-be.s3.amazonaws.com)|52.219.66.56|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102320961 (98M) [application/octet-stream]\n",
            "Saving to: ‘data.zip’\n",
            "\n",
            "data.zip            100%[===================>]  97.58M  11.2MB/s    in 11s     \n",
            "\n",
            "2022-02-06 21:44:24 (9.01 MB/s) - ‘data.zip’ saved [102320961/102320961]\n",
            "\n",
            "Archive:  ./data.zip\n",
            "   creating: Embold_Participant's_Dataset/\n",
            "  inflating: Embold_Participant's_Dataset/sample submission.csv  \n",
            "  inflating: __MACOSX/Embold_Participant's_Dataset/._sample submission.csv  \n",
            "  inflating: Embold_Participant's_Dataset/embold_train_extra.json  \n",
            "  inflating: __MACOSX/Embold_Participant's_Dataset/._embold_train_extra.json  \n",
            "  inflating: Embold_Participant's_Dataset/embold_test.json  \n",
            "  inflating: __MACOSX/Embold_Participant's_Dataset/._embold_test.json  \n",
            "  inflating: Embold_Participant's_Dataset/embold_train.json  \n",
            "  inflating: __MACOSX/Embold_Participant's_Dataset/._embold_train.json  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install fasttext\n",
        "! pip install fasttext"
      ],
      "metadata": {
        "id": "DTKXZusSQNl1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a224c9cc-d5df-4d3e-e594-4f9e6f11d2fa"
      },
      "id": "DTKXZusSQNl1",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 20.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 10.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 3.4 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.9.1-py2.py3-none-any.whl (211 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3128296 sha256=a421330ee2f092b2eaa0489f4414a590b2e602c748297c6179c5b934ff1734db\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.9.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "I0YkX5CXepfi"
      },
      "id": "I0YkX5CXepfi"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "07ab578b-d556-407c-a357-77c15b17be3b",
      "metadata": {
        "id": "07ab578b-d556-407c-a357-77c15b17be3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0000ae30-8511-4bff-b40c-b8e36cca37db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf \n",
        "\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Dense, Dropout, SpatialDropout1D\n",
        "from tensorflow.keras.layers import GlobalMaxPool1D, MaxPooling1D, GlobalMaxPooling1D, Conv1D\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import fasttext\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import pandas as pd\n",
        "import re\n",
        "import numpy as np\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "import string\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "\n",
        "# Word Embedding\n",
        "from gensim.models import KeyedVectors\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "NIvkU8e2eSm3"
      },
      "id": "NIvkU8e2eSm3"
    },
    {
      "cell_type": "code",
      "source": [
        "# merge data\n",
        "data_small_df = pd.read_json('./data/embold_train.json').reset_index(drop=True)\n",
        "data_large_df = pd.read_json('./data/embold_train_extra.json').reset_index(drop=True)\n",
        "data_df = data_small_df.append(data_large_df)\n",
        "data_df['text'] = data_df['title']+' '+data_df['body']\n",
        "data_df['text_length'] = data_df['text'].apply(lambda text_input: len(text_input.split()))"
      ],
      "metadata": {
        "id": "yBYACIpBxCaa"
      },
      "id": "yBYACIpBxCaa",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add constraint on data: Debug \n",
        "data_df= data_df[:10000]"
      ],
      "metadata": {
        "id": "JBy3cib260lG"
      },
      "id": "JBy3cib260lG",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preprocess"
      ],
      "metadata": {
        "id": "g3UJaMTV6B9F"
      },
      "id": "g3UJaMTV6B9F"
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_list = stopwords.words('english')\n",
        "\n",
        "def clean_text(text, lowercase=True, stop_words=True, links=True, numbers=True):\n",
        "    text = text.replace(\"\\\\r\", \"\")\n",
        "    if lowercase:\n",
        "        text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    if links:\n",
        "        text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub('<.*?>+', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\n', '', text)\n",
        "    if numbers:\n",
        "       text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    if stop_words:\n",
        "        text = \" \".join([word for word in text.split() if word not in stopwords_list])\n",
        "    return text"
      ],
      "metadata": {
        "id": "IGXA192_6FX0"
      },
      "id": "IGXA192_6FX0",
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df['text_clean'] = data_df['text'].progress_apply(lambda text: clean_text(text))"
      ],
      "metadata": {
        "id": "qFrcOt1w9i8n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "c1975071d10f4a6aaf6bd13011388486",
            "418dc9a21c554e308999bfdea8da4827",
            "17a831f9b45d4284a294edd1c9f02378",
            "6f76761f48ee49be98292d0c21197ccd",
            "c9784abd917c4eafb98b4bef195367dc",
            "55d849acbfcc46a2ada63d74b466d35d",
            "daf9ee4153ec4a0fb6577abc198fffb4",
            "0a935677a8484fbab8fbedac1726ea2c",
            "9db054ec6c5d4f538434c659a7f28ad3",
            "c5bb06f7b1394f698dfc1715943e89ae",
            "0e05e006afb840bab83a0bfa2ef24fb8"
          ]
        },
        "outputId": "c29b95fe-03f2-417d-8588-31fc97177a10"
      },
      "id": "qFrcOt1w9i8n",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1975071d10f4a6aaf6bd13011388486",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/1000 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "\n",
        "X = data_df['text_clean'].values\n",
        "y = label_encoder.fit_transform(data_df['label'])\n",
        "\n",
        "X_train, X_test, y_train, y_test  = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2\n"
      ],
      "metadata": {
        "id": "OtPg_moO-T3Y"
      },
      "id": "OtPg_moO-T3Y",
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d1796d3e-6920-44fd-96a0-892bb67ce303",
      "metadata": {
        "id": "d1796d3e-6920-44fd-96a0-892bb67ce303"
      },
      "source": [
        "## FastText Embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download Fasstext Model"
      ],
      "metadata": {
        "id": "S5mrfStCR2zA"
      },
      "id": "S5mrfStCR2zA"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "8d9e7770-c460-44ec-b8b4-213befad7c44",
      "metadata": {
        "id": "8d9e7770-c460-44ec-b8b4-213befad7c44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4fb9e78-3e8f-44ff-bf01-bc65fbb4d4b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-02-06 21:47:32--  https://www.dropbox.com/s/6aaucelizfx7xl6/en_vectors_v3.bin\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.3.18, 2620:100:601b:18::a27d:812\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.3.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/6aaucelizfx7xl6/en_vectors_v3.bin [following]\n",
            "--2022-02-06 21:47:32--  https://www.dropbox.com/s/raw/6aaucelizfx7xl6/en_vectors_v3.bin\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb73641466c926079285ba3cf7d.dl.dropboxusercontent.com/cd/0/inline/BfPm5LXLWm8rVNI_vuBTnWcOdqu3A9-_8CzQxbui39kyEVynkFwfC3egtxMzzaxiTQm6WVa6CGOury2LEBGidQyN9Uh2RDq4GzE30qysT-_owdeJ16wgUNFipj5YlPcBOdBCC6KF7Vme4rO_mHBx--mB/file# [following]\n",
            "--2022-02-06 21:47:32--  https://ucb73641466c926079285ba3cf7d.dl.dropboxusercontent.com/cd/0/inline/BfPm5LXLWm8rVNI_vuBTnWcOdqu3A9-_8CzQxbui39kyEVynkFwfC3egtxMzzaxiTQm6WVa6CGOury2LEBGidQyN9Uh2RDq4GzE30qysT-_owdeJ16wgUNFipj5YlPcBOdBCC6KF7Vme4rO_mHBx--mB/file\n",
            "Resolving ucb73641466c926079285ba3cf7d.dl.dropboxusercontent.com (ucb73641466c926079285ba3cf7d.dl.dropboxusercontent.com)... 162.125.3.15, 2620:100:6018:15::a27d:30f\n",
            "Connecting to ucb73641466c926079285ba3cf7d.dl.dropboxusercontent.com (ucb73641466c926079285ba3cf7d.dl.dropboxusercontent.com)|162.125.3.15|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: /cd/0/inline2/BfNL8tHQRlsxQ2suOquidF86WfCOAU8SljubhFYIhYk3sHMfBoMkkErVPw5qJv9-H4HIjASgwn7l9RVOl6ktyJk25Y1ynq7vmkjH8YzXrKUb92c8t47tVzKKByHG6szSu34R-QS9QEEEO_rEUnxd4uhQ7BY8jEoX5Uh4utpDfIRvEfjOs4aKbm7gVHHB1CC9K03Tb0FORMMAuZu9P1aqZs2JlxdEgGb1iLqi1fP3zy0TG5Y5am2tj9w6vkEzo9yp8JqjP9iyckHzbSvAblwY-p_u_wbpkjIsBi4qwQkgyZAGfmqHnWIDcm96iMWmRHKGysa-EqtED0x3LqepCJS8BAzuKBjNyHeIrxSRFyIEt4M0_SrslkDgOADjtrw5DMV-Dy4/file [following]\n",
            "--2022-02-06 21:47:32--  https://ucb73641466c926079285ba3cf7d.dl.dropboxusercontent.com/cd/0/inline2/BfNL8tHQRlsxQ2suOquidF86WfCOAU8SljubhFYIhYk3sHMfBoMkkErVPw5qJv9-H4HIjASgwn7l9RVOl6ktyJk25Y1ynq7vmkjH8YzXrKUb92c8t47tVzKKByHG6szSu34R-QS9QEEEO_rEUnxd4uhQ7BY8jEoX5Uh4utpDfIRvEfjOs4aKbm7gVHHB1CC9K03Tb0FORMMAuZu9P1aqZs2JlxdEgGb1iLqi1fP3zy0TG5Y5am2tj9w6vkEzo9yp8JqjP9iyckHzbSvAblwY-p_u_wbpkjIsBi4qwQkgyZAGfmqHnWIDcm96iMWmRHKGysa-EqtED0x3LqepCJS8BAzuKBjNyHeIrxSRFyIEt4M0_SrslkDgOADjtrw5DMV-Dy4/file\n",
            "Reusing existing connection to ucb73641466c926079285ba3cf7d.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/octet-stream]\n",
            "Saving to: ‘en_vectors_v3.bin.1’\n",
            "\n",
            "en_vectors_v3.bin.1     [            <=>     ] 337.06M  80.5MB/s    in 4.3s    \n",
            "\n",
            "2022-02-06 21:47:37 (78.6 MB/s) - ‘en_vectors_v3.bin.1’ saved [353437130]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://www.dropbox.com/s/6aaucelizfx7xl6/en_vectors_v3.bin"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDING_LEN = 128 "
      ],
      "metadata": {
        "id": "MLdM-i-9FWpT"
      },
      "id": "MLdM-i-9FWpT",
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load FastText Model"
      ],
      "metadata": {
        "id": "GXOumsIWR9YX"
      },
      "id": "GXOumsIWR9YX"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "7d0d02a1-504f-4da8-9254-f31b7386cd32",
      "metadata": {
        "id": "7d0d02a1-504f-4da8-9254-f31b7386cd32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a334c707-a811-405b-ceaf-2a5bdf4de019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "model_skipgram = fasttext.load_model('en_vectors_v3.bin')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit Keras Tokenizer on X_train\n",
        "\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=3000)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print('Vocabulary Size : {}'.format(vocab_size))"
      ],
      "metadata": {
        "id": "_WQEhOzDS8Yw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c16d246e-4dea-4786-974a-1d1e44f11e9b"
      },
      "id": "_WQEhOzDS8Yw",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size : 6345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_comments = tokenizer.texts_to_sequences(X_train)\n",
        "\n",
        "# example of encoded comments\n",
        "print(\"Comment : {}\".format(X_train[1]))\n",
        "print(\"Corresponding Encoding : {}\".format(encoded_comments[1]))"
      ],
      "metadata": {
        "id": "Bs7z2ltRTNCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0757ecc6-8300-4b06-9107-db8f56734e9b"
      },
      "id": "Bs7z2ltRTNCA",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Comment : could graphqlrequestentity make setrequestmethod public method team use framework compose query graphql api call saw setrequestmethod method graphqlrequestentity access package graphqltemplate call change request method program use feignhystrix http call means use nodes compose query understanding enough change setrequestmethod public method initial process finish graphqlrequestentity constructor method could expose set requestmethod query mutate builder\n",
            "Corresponding Encoding : [26, 1397, 33, 1398, 130, 104, 295, 7, 558, 1943, 151, 51, 36, 918, 1398, 104, 1397, 381, 244, 36, 37, 34, 104, 490, 7, 152, 36, 429, 7, 652, 1943, 151, 919, 430, 37, 1398, 130, 104, 1944, 353, 1945, 1397, 920, 104, 26, 1946, 16, 151, 1101]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "48de0848-6da0-4c32-b156-d2bdf08a959d",
      "metadata": {
        "id": "48de0848-6da0-4c32-b156-d2bdf08a959d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f78bf0c-a761-4685-8195-dd6891e58479"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padding Shape: (600, 271)\n"
          ]
        }
      ],
      "source": [
        "# padding\n",
        "SENT_MAX_LEN = max([len(sent) for sent in encoded_comments])\n",
        "padded_sequence = pad_sequences(encoded_comments, maxlen=SENT_MAX_LEN, padding='post')\n",
        "print('Padding Shape: {}'.format(padded_sequence.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "114a59a6-c98a-4659-9eff-ff976fb4b8e6",
      "metadata": {
        "id": "114a59a6-c98a-4659-9eff-ff976fb4b8e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40065678-cccf-4631-e3cc-89ca1ed2b1e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding Matrix Shape is: (6345, 128)\n"
          ]
        }
      ],
      "source": [
        "# initial embedding matrix\n",
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_LEN))\n",
        "\n",
        "for word, i in tokenizer.word_index.items():\n",
        "  embedding_vector = model_skipgram.get_word_vector(word)\n",
        "  # words that cannot be found will be set to 0\n",
        "  if embedding_vector is not None:\n",
        "    embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print(f\"Embedding Matrix Shape is: {embedding_matrix.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "81b4d562-56d1-4a94-81d3-7d5899399d50",
      "metadata": {
        "id": "81b4d562-56d1-4a94-81d3-7d5899399d50"
      },
      "outputs": [],
      "source": [
        "# Same procedure with a Unique Tokenizer on Evaluation data\n",
        "\n",
        "tokenizer.texts_to_matrix(X_val)\n",
        "eval_encoded_comments = tokenizer.texts_to_sequences(X_val)\n",
        "eval_padded_sequence = pad_sequences(eval_encoded_comments, maxlen=SENT_MAX_LEN, padding='post')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "ae83164d-2b20-4b8b-be62-8317a0c3b29a",
      "metadata": {
        "id": "ae83164d-2b20-4b8b-be62-8317a0c3b29a"
      },
      "outputs": [],
      "source": [
        "# Same procedure with a Unique Tokenizer on Test data\n",
        "\n",
        "tokenizer.texts_to_matrix(X_test)\n",
        "test_encoded_comments = tokenizer.texts_to_sequences(X_test)\n",
        "test_padded_sequence = pad_sequences(test_encoded_comments, maxlen=SENT_MAX_LEN, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LSTM Model Architecture"
      ],
      "metadata": {
        "id": "adHsUq4GUScc"
      },
      "id": "adHsUq4GUScc"
    },
    {
      "cell_type": "code",
      "source": [
        "# LSTM constants\n",
        "LSTM_UNITS = 32"
      ],
      "metadata": {
        "id": "dYh33GkGioq-"
      },
      "id": "dYh33GkGioq-",
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_1 = Sequential()\n",
        "model_1.add(Embedding(vocab_size, EMBEDDING_LEN, input_length=SENT_MAX_LEN, weights=[embedding_matrix], trainable=True))\n",
        "model_1.add(Bidirectional(LSTM(EMBEDDING_LEN, return_sequences=True, input_shape=(None, 1))))\n",
        "model_1.add(Dropout(0.2))\n",
        "model_1.add(Bidirectional(LSTM(LSTM_UNITS)))\n",
        "model_1.add(Dropout(0.2))\n",
        "model_1.add(Dense(EMBEDDING_LEN, activation='relu'))\n",
        "model_1.add(Dropout(0.1))\n",
        "model_1.add(Dense(3, activation='sigmoid'))\n",
        "model_1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_1.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tkv0Pr89RR_S",
        "outputId": "66b99f2b-0df5-4af5-affa-aa3c1da42f80"
      },
      "id": "Tkv0Pr89RR_S",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 271, 128)          812160    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 271, 256)         263168    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 271, 256)          0         \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 64)               73984     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 3)                 387       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,158,019\n",
            "Trainable params: 1,158,019\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit LSTM Model\n",
        "You can run the cell bellow as much as you want. keep track on validation accuracy and also change the `epochs`. I got my best result in most of the run times at 5th and 10th epochs."
      ],
      "metadata": {
        "id": "RJyJIjngVuUm"
      },
      "id": "RJyJIjngVuUm"
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_hot = np.eye(3)[y_train] # One-Hot\n",
        "y_val_hot =  np.eye(3)[y_val] # One-Hot\n",
        "y_test_hot = np.eye(3)[y_test] # One-Hot"
      ],
      "metadata": {
        "id": "hH-wi17T4Rpb"
      },
      "id": "hH-wi17T4Rpb",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "6ede4981-e708-4956-9736-d7b0b6a65f59",
      "metadata": {
        "id": "6ede4981-e708-4956-9736-d7b0b6a65f59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2d8161-52e8-4942-e292-ac95934b2323"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "19/19 [==============================] - 14s 382ms/step - loss: 0.9638 - accuracy: 0.4583 - val_loss: 0.9779 - val_accuracy: 0.4500\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 5s 287ms/step - loss: 0.9177 - accuracy: 0.4700 - val_loss: 0.9434 - val_accuracy: 0.6350\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 5s 284ms/step - loss: 0.8321 - accuracy: 0.6583 - val_loss: 0.8211 - val_accuracy: 0.6400\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 5s 285ms/step - loss: 0.6592 - accuracy: 0.7517 - val_loss: 0.7764 - val_accuracy: 0.7000\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 5s 285ms/step - loss: 0.5248 - accuracy: 0.8183 - val_loss: 0.8376 - val_accuracy: 0.6500\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e50893fd0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "model_1.fit(\n",
        "    padded_sequence, \n",
        "    y_train_hot, \n",
        "    batch_size=32, \n",
        "    epochs=5, \n",
        "    validation_data=(eval_padded_sequence, y_val_hot)\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_1, acc_1 = model_1.evaluate(test_padded_sequence, y_test_hot, verbose=0)\n",
        "print(f'Test Accuracy: {acc_1}')"
      ],
      "metadata": {
        "id": "tAko7El4vMkr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a87a2ec-f24e-4299-86f0-7b6eb053f4d4"
      },
      "id": "tAko7El4vMkr",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6299999952316284\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_1 = model_1.predict(test_padded_sequence).argmax(axis=1)\n",
        "print(confusion_matrix(y_true=y_test, y_pred=y_pred_1))\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred_1))"
      ],
      "metadata": {
        "id": "pqto7tgjCi4j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fadb99f6-ba49-4c44-b209-6c1ab7d3950d"
      },
      "id": "pqto7tgjCi4j",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[80  8  0]\n",
            " [47 46  0]\n",
            " [12  7  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.91      0.70        88\n",
            "           1       0.75      0.49      0.60        93\n",
            "           2       0.00      0.00      0.00        19\n",
            "\n",
            "    accuracy                           0.63       200\n",
            "   macro avg       0.44      0.47      0.43       200\n",
            "weighted avg       0.60      0.63      0.59       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN Model Architecture"
      ],
      "metadata": {
        "id": "C_ni4QYf_xNk"
      },
      "id": "C_ni4QYf_xNk"
    },
    {
      "cell_type": "code",
      "source": [
        "## CNN Constants\n",
        "KERNEL_SIZE = 3\n",
        "FILTERS = 256"
      ],
      "metadata": {
        "id": "MVk-i5iE9ayI"
      },
      "id": "MVk-i5iE9ayI",
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Embedding(vocab_size, embedding_matrix.shape[1], weights=[embedding_matrix], trainable=False))\n",
        "model_2.add(Conv1D(filters=FILTERS, kernel_size=KERNEL_SIZE, activation='relu'))\n",
        "model_2.add(GlobalMaxPooling1D())\n",
        "model_2.add(Dense(FILTERS, activation='relu'))\n",
        "model_2.add(Dense(3, activation='sigmoid'))\n",
        "model_2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_2.summary()"
      ],
      "metadata": {
        "id": "lfs4V5H37reB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af4ec1ed-1245-4135-d41e-6fb7d0a045c2"
      },
      "id": "lfs4V5H37reB",
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, None, 128)         812160    \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, None, 256)         98560     \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               65792     \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 771       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 977,283\n",
            "Trainable params: 165,123\n",
            "Non-trainable params: 812,160\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fit CNN Model\n",
        "You can run the cell bellow as much as you want. keep track on validation accuracy and also change the `epochs`. I got my best result in most of the run times at 5th epoch."
      ],
      "metadata": {
        "id": "akaz6n0t_bTS"
      },
      "id": "akaz6n0t_bTS"
    },
    {
      "cell_type": "code",
      "source": [
        "model_2.fit(\n",
        "    padded_sequence, \n",
        "    y_train_hot, \n",
        "    batch_size=32, \n",
        "    epochs=5, \n",
        "    validation_data=(eval_padded_sequence, y_val_hot)\n",
        "    )"
      ],
      "metadata": {
        "id": "dbVoK7r29R1S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6934ca6e-8a95-43e1-bd66-e9bfd6ef85c7"
      },
      "id": "dbVoK7r29R1S",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "19/19 [==============================] - 7s 25ms/step - loss: 0.9478 - accuracy: 0.4817 - val_loss: 0.9490 - val_accuracy: 0.5500\n",
            "Epoch 2/5\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.7710 - accuracy: 0.7183 - val_loss: 0.9173 - val_accuracy: 0.6050\n",
            "Epoch 3/5\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.5875 - accuracy: 0.8033 - val_loss: 0.8755 - val_accuracy: 0.6250\n",
            "Epoch 4/5\n",
            "19/19 [==============================] - 0s 13ms/step - loss: 0.3856 - accuracy: 0.9000 - val_loss: 0.7849 - val_accuracy: 0.6800\n",
            "Epoch 5/5\n",
            "19/19 [==============================] - 0s 15ms/step - loss: 0.1760 - accuracy: 0.9800 - val_loss: 0.8041 - val_accuracy: 0.6850\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7e4fff4cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_2, acc_2 = model_2.evaluate(test_padded_sequence, y_test_hot, verbose=0)\n",
        "print('Test Accuracy: %f' % (acc_2*100))"
      ],
      "metadata": {
        "id": "S0E9HNy_-NbD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bfacc6c-d2a1-44de-b46e-2bc15350a47b"
      },
      "id": "S0E9HNy_-NbD",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 64.499998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_2 = model_2.predict(test_padded_sequence).argmax(axis=1)\n",
        "print(confusion_matrix(y_true=y_test, y_pred=y_pred_2))\n",
        "print(classification_report(y_true=y_test, y_pred=y_pred_2))"
      ],
      "metadata": {
        "id": "z9sTL8h4Ae6q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83f52b04-9924-42b1-ca68-3c44f1eb16f1"
      },
      "id": "z9sTL8h4Ae6q",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[71 17  0]\n",
            " [35 58  0]\n",
            " [ 8 11  0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.81      0.70        88\n",
            "           1       0.67      0.62      0.65        93\n",
            "           2       0.00      0.00      0.00        19\n",
            "\n",
            "    accuracy                           0.65       200\n",
            "   macro avg       0.43      0.48      0.45       200\n",
            "weighted avg       0.59      0.65      0.61       200\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "LSTM_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c1975071d10f4a6aaf6bd13011388486": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_418dc9a21c554e308999bfdea8da4827",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_17a831f9b45d4284a294edd1c9f02378",
              "IPY_MODEL_6f76761f48ee49be98292d0c21197ccd",
              "IPY_MODEL_c9784abd917c4eafb98b4bef195367dc"
            ]
          }
        },
        "418dc9a21c554e308999bfdea8da4827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "17a831f9b45d4284a294edd1c9f02378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_55d849acbfcc46a2ada63d74b466d35d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_daf9ee4153ec4a0fb6577abc198fffb4"
          }
        },
        "6f76761f48ee49be98292d0c21197ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0a935677a8484fbab8fbedac1726ea2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9db054ec6c5d4f538434c659a7f28ad3"
          }
        },
        "c9784abd917c4eafb98b4bef195367dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c5bb06f7b1394f698dfc1715943e89ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [00:00&lt;00:00, 2844.46it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e05e006afb840bab83a0bfa2ef24fb8"
          }
        },
        "55d849acbfcc46a2ada63d74b466d35d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "daf9ee4153ec4a0fb6577abc198fffb4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0a935677a8484fbab8fbedac1726ea2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9db054ec6c5d4f538434c659a7f28ad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c5bb06f7b1394f698dfc1715943e89ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e05e006afb840bab83a0bfa2ef24fb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}